{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeeff11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from reconstruction.utils import binvox_rw\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ca5bb",
   "metadata": {},
   "source": [
    "### Ver nuestro conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affd6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
      "Counter({'chair': 889,\n",
      "         'sofa': 680,\n",
      "         'bed': 515,\n",
      "         'monitor': 465,\n",
      "         'table': 392,\n",
      "         'toilet': 344,\n",
      "         'desk': 200,\n",
      "         'dresser': 200,\n",
      "         'night_stand': 200,\n",
      "         'bathtub': 106})\n"
     ]
    }
   ],
   "source": [
    "path = 'ModelNet10/'\n",
    "labels = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "files = [os.path.join(path,l,'train',ll) for l in labels\n",
    "         for ll in os.listdir(os.path.join(path, l, 'train'))\n",
    "         if ll[-4:] == '.off']\n",
    "\n",
    "print(labels)\n",
    "pprint(Counter([f.split('ModelNet10/')[1].split('\\\\')[0] for f in files]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839bd00",
   "metadata": {},
   "source": [
    "### Leer y convertir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89029324",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = random.choice(files)\n",
    "\n",
    "def check_fix_file(file):\n",
    "    with open(file) as f:\n",
    "        l1 = f.readline()\n",
    "        l2 = f.readlines()\n",
    "\n",
    "    if l1 != 'OFF\\n' and l1[:3] == 'OFF':\n",
    "        out = 'OFF\\n'\n",
    "        out += l1.split('OFF')[1]\n",
    "        out += ''.join(l2)\n",
    "        with open(file, 'w') as f:\n",
    "            f.write(out)\n",
    "\n",
    "def voxels_from_file(file, voxsize):\n",
    "    cmd = f'C:/Users/Jefferson/MachineL/binbox/binvox -d {voxsize} -cb -e {file}'\n",
    "    check_fix_file(file)\n",
    "    out_file = file.split('.')[0] + '.binvox'\n",
    "            \n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "\n",
    "    t = os.system(cmd)\n",
    "    \n",
    "    if t == 0:\n",
    "        with open(out_file, 'rb') as f:\n",
    "            d = binvox_rw.read_as_3d_array(f).data\n",
    "        \n",
    "        os.remove(out_file)\n",
    "        return 1, d\n",
    "    else:\n",
    "        return 0, None\n",
    "\n",
    "voxels = voxels_from_file(file, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7e5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label = lambda x: x.split('ModelNet')[1][3:].split('\\\\')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30139b7",
   "metadata": {},
   "source": [
    "### Convertir todo el conjunto de datos de muebles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0204c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186dc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multithreading(func, args, workers):\n",
    "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        res = executor.map(func, args)\n",
    "    return list(res)\n",
    "\n",
    "get_label = lambda x: x.split('ModelNet')[1][3:].split('\\\\')[0]\n",
    "\n",
    "def get_voxels(files, voxsize):\n",
    "    data = np.ndarray((0, *[voxsize]*3), dtype=np.bool)\n",
    "    labels = []\n",
    "    errors = []\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        res = voxels_from_file(file, voxsize)\n",
    "        if res[0] == 1:\n",
    "            labels.append(get_label(file))\n",
    "            data = np.vstack([data, res[1].reshape((1, *res[1].shape))])\n",
    "        else:\n",
    "            errors.append(file)\n",
    "\n",
    "    return labels, data, errors\n",
    "\n",
    "get_voxels_parallel = lambda x: get_voxels(*x)\n",
    "\n",
    "def convert_all(path, voxsize):\n",
    "    out_file = os.path.join(path, 'voxels.npy')\n",
    "    labels = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "    train_files = [os.path.join(path,l,'train',ll) for l in labels\n",
    "                   for ll in os.listdir(os.path.join(path, l, 'train'))\n",
    "                   if ll[-4:] == '.off']\n",
    "    test_files = [os.path.join(path,l,'test',ll) for l in labels\n",
    "                   for ll in os.listdir(os.path.join(path, l, 'test'))\n",
    "                   if ll[-4:] == '.off']\n",
    "\n",
    "    print(f'train: {len(train_files)}, test: {len(test_files)}')\n",
    "    \n",
    "    n_cpu = multiprocessing.cpu_count()\n",
    "    output = {}\n",
    "    \n",
    "    for data_files, data_name in zip([train_files, test_files], ['train', 'test']):\n",
    "        t0 = time()\n",
    "        print(f'Launching {n_cpu} threads for {data_name} set...', end='')\n",
    "        thread_size = math.ceil(len(data_files) / n_cpu)\n",
    "        args = [(data_files[i*thread_size:(i+1)*thread_size], voxsize) for i in range(n_cpu)]\n",
    "        res = multithreading(get_voxels_parallel, args, n_cpu)\n",
    "        labels = []\n",
    "        data = np.ndarray((0, *[voxsize]*3), dtype=np.bool)\n",
    "        errors = []\n",
    "\n",
    "        for l, d, e in res:\n",
    "            labels += l\n",
    "            data = np.vstack([data, d])\n",
    "            errors += e\n",
    "            \n",
    "        output[data_name] = {'labels': labels, 'data': data, 'errors': errors}\n",
    "        \n",
    "        print('(%.2fs)' % (time() - t0))\n",
    "    \n",
    "    np.save(out_file, output)    \n",
    "    print('\\nSaved on: %s (%.2fM)' % (out_file, os.path.getsize(out_file) / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9fb6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3991, test: 908\n",
      "Launching 12 threads for train set..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jefferson\\AppData\\Local\\Temp\\ipykernel_17116\\2069273253.py:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data = np.ndarray((0, *[voxsize]*3), dtype=np.bool)\n",
      "C:\\Users\\Jefferson\\AppData\\Local\\Temp\\ipykernel_17116\\2069273253.py:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data = np.ndarray((0, *[voxsize]*3), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208.45s)\n",
      "Launching 12 threads for test set...(40.62s)\n",
      "\n",
      "Saved on: ModelNet10/voxels.npy (153.17M)\n"
     ]
    }
   ],
   "source": [
    "convert_all('ModelNet10/', voxsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69bd518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofa\n"
     ]
    }
   ],
   "source": [
    "modelnet10 = np.load('ModelNet10/voxels.npy',allow_pickle=True).item()\n",
    "idx = random.choice(range(len(modelnet10['train']['labels'])))\n",
    "print(modelnet10['train']['labels'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d586e314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3991\n"
     ]
    }
   ],
   "source": [
    "print(len(modelnet10['train']['labels']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
